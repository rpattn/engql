// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: entity_ingest_batches.sql

package db

import (
	"context"

	"github.com/google/uuid"
	"github.com/jackc/pgx/v5/pgtype"
)

const EntityIngestBatchStats = `-- name: EntityIngestBatchStats :one
SELECT
    COUNT(*) AS total_batches,
    COUNT(*) FILTER (WHERE status IN ('PENDING', 'FLUSHING')) AS in_progress_batches,
    COUNT(*) FILTER (WHERE status = 'COMPLETED') AS completed_batches,
    COUNT(*) FILTER (WHERE status = 'FAILED') AS failed_batches,
    COALESCE(SUM(rows_staged), 0)::bigint AS total_rows_staged,
    COALESCE(SUM(rows_flushed), 0)::bigint AS total_rows_flushed
FROM entity_ingest_batches
WHERE ($1::uuid IS NULL OR organization_id = $1)
`

type EntityIngestBatchStatsRow struct {
	TotalBatches      int64 `json:"total_batches"`
	InProgressBatches int64 `json:"in_progress_batches"`
	CompletedBatches  int64 `json:"completed_batches"`
	FailedBatches     int64 `json:"failed_batches"`
	TotalRowsStaged   int64 `json:"total_rows_staged"`
	TotalRowsFlushed  int64 `json:"total_rows_flushed"`
}

func (q *Queries) EntityIngestBatchStats(ctx context.Context, organizationID pgtype.UUID) (EntityIngestBatchStatsRow, error) {
	row := q.db.QueryRow(ctx, EntityIngestBatchStats, organizationID)
	var i EntityIngestBatchStatsRow
	err := row.Scan(
		&i.TotalBatches,
		&i.InProgressBatches,
		&i.CompletedBatches,
		&i.FailedBatches,
		&i.TotalRowsStaged,
		&i.TotalRowsFlushed,
	)
	return i, err
}

const InsertEntityIngestBatch = `-- name: InsertEntityIngestBatch :exec

INSERT INTO entity_ingest_batches (
    id,
    organization_id,
    schema_id,
    entity_type,
    file_name,
    rows_staged,
    skip_validation,
    status
) VALUES (
    $1,
    $2,
    $3,
    $4,
    $5,
    $6,
    $7,
    'PENDING'
)
`

type InsertEntityIngestBatchParams struct {
	ID             uuid.UUID   `json:"id"`
	OrganizationID uuid.UUID   `json:"organization_id"`
	SchemaID       uuid.UUID   `json:"schema_id"`
	EntityType     string      `json:"entity_type"`
	FileName       pgtype.Text `json:"file_name"`
	RowsStaged     int32       `json:"rows_staged"`
	SkipValidation bool        `json:"skip_validation"`
}

// Track background flush batches for staged entity ingestion.
func (q *Queries) InsertEntityIngestBatch(ctx context.Context, arg InsertEntityIngestBatchParams) error {
	_, err := q.db.Exec(ctx, InsertEntityIngestBatch,
		arg.ID,
		arg.OrganizationID,
		arg.SchemaID,
		arg.EntityType,
		arg.FileName,
		arg.RowsStaged,
		arg.SkipValidation,
	)
	return err
}

const ListEntityIngestBatchesByStatus = `-- name: ListEntityIngestBatchesByStatus :many
SELECT
    id,
    organization_id,
    schema_id,
    entity_type,
    file_name,
    rows_staged,
    rows_flushed,
    skip_validation,
    status,
    error_message,
    enqueued_at,
    started_at,
    completed_at,
    updated_at
FROM entity_ingest_batches
WHERE status = ANY($1::text[])
  AND ($2::uuid IS NULL OR organization_id = $2)
ORDER BY enqueued_at DESC
LIMIT $4 OFFSET $3
`

type ListEntityIngestBatchesByStatusParams struct {
	Statuses       []string    `json:"statuses"`
	OrganizationID pgtype.UUID `json:"organization_id"`
	PageOffset     int32       `json:"page_offset"`
	PageLimit      int32       `json:"page_limit"`
}

func (q *Queries) ListEntityIngestBatchesByStatus(ctx context.Context, arg ListEntityIngestBatchesByStatusParams) ([]EntityIngestBatch, error) {
	rows, err := q.db.Query(ctx, ListEntityIngestBatchesByStatus,
		arg.Statuses,
		arg.OrganizationID,
		arg.PageOffset,
		arg.PageLimit,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []EntityIngestBatch{}
	for rows.Next() {
		var i EntityIngestBatch
		if err := rows.Scan(
			&i.ID,
			&i.OrganizationID,
			&i.SchemaID,
			&i.EntityType,
			&i.FileName,
			&i.RowsStaged,
			&i.RowsFlushed,
			&i.SkipValidation,
			&i.Status,
			&i.ErrorMessage,
			&i.EnqueuedAt,
			&i.StartedAt,
			&i.CompletedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const MarkEntityIngestBatchCompleted = `-- name: MarkEntityIngestBatchCompleted :exec
UPDATE entity_ingest_batches
SET status = 'COMPLETED',
    rows_flushed = $1,
    completed_at = NOW(),
    updated_at = NOW(),
    error_message = NULL
WHERE id = $2
`

type MarkEntityIngestBatchCompletedParams struct {
	RowsFlushed int32     `json:"rows_flushed"`
	ID          uuid.UUID `json:"id"`
}

func (q *Queries) MarkEntityIngestBatchCompleted(ctx context.Context, arg MarkEntityIngestBatchCompletedParams) error {
	_, err := q.db.Exec(ctx, MarkEntityIngestBatchCompleted, arg.RowsFlushed, arg.ID)
	return err
}

const MarkEntityIngestBatchFailed = `-- name: MarkEntityIngestBatchFailed :exec
UPDATE entity_ingest_batches
SET status = 'FAILED',
    error_message = $1,
    completed_at = NOW(),
    updated_at = NOW()
WHERE id = $2
`

type MarkEntityIngestBatchFailedParams struct {
	ErrorMessage pgtype.Text `json:"error_message"`
	ID           uuid.UUID   `json:"id"`
}

func (q *Queries) MarkEntityIngestBatchFailed(ctx context.Context, arg MarkEntityIngestBatchFailedParams) error {
	_, err := q.db.Exec(ctx, MarkEntityIngestBatchFailed, arg.ErrorMessage, arg.ID)
	return err
}

const MarkEntityIngestBatchFlushing = `-- name: MarkEntityIngestBatchFlushing :exec
UPDATE entity_ingest_batches
SET status = 'FLUSHING',
    started_at = NOW(),
    updated_at = NOW()
WHERE id = $1
`

func (q *Queries) MarkEntityIngestBatchFlushing(ctx context.Context, id uuid.UUID) error {
	_, err := q.db.Exec(ctx, MarkEntityIngestBatchFlushing, id)
	return err
}
